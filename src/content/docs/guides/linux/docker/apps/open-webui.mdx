---
title: Open WebUI
description: "Open WebUI is an extensible, feature-rich and user-friendly self-hosted AI platform designed to operate entirely offline. It supports various LLM runners like Ollama and OpenAI-compatible APIs, with built-in inference engine for RAG, making it a powerful AI deployment solution."
references:
  - href: https://github.com/open-webui/open-webui
    label: GitHub repo
  - href: https://docs.openwebui.com/
    label: Docs
  - href: https://ollama.com/download
    label: Ollama download
---

import OpenWebUI from "@/components/guides/open-webui.astro";
import ReferenceLinks from "@/components/guides/reference-links.astro";
import { Code } from "@astrojs/starlight/components";
import yaml from "/src/files/compose/open-webui.yml?raw";

<p>{frontmatter.description}</p>

### References

<ReferenceLinks references={frontmatter.references} />

## Create/change directory for Open WebUI

```sh
mkdir -p {{{DOCKER_PATH_VAR}}}/open-webui && cd {{{DOCKER_PATH_VAR}}}/open-webui
```

## Create docker-compose.yml

```sh
nano docker-compose.yml
```

## Copy docker-compose.yml

<Code lang="yml" title="docker-compose.yml" code={yaml} />

## Start container

```sh
docker compose up -d
```

## Open web ui

<OpenWebUI port="3007" />
